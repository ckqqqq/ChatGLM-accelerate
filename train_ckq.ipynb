{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Load Model From huggingface\n",
    "import os\n",
    "import tqdm\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import peft\n",
    "import loralib as lora\n",
    "from peft import LoraConfig\n",
    "\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import accelerate\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tokenization_chatglm import ChatGLMTokenizer\n",
    "import transformers\n",
    "# from tokenizaion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokenizaion\n",
    "\n",
    "checkpoint = \"THUDM/chatglm-6b\"\n",
    "mixed_precision = 'bf16'\n",
    "\n",
    "accumulate_step = 8\n",
    "MAX_LENGTH = 750\n",
    "\n",
    "# from peft import LoraConfig,get_peft_model\n",
    "config = LoraConfig(\n",
    "    peft_type=\"LORA\", \n",
    "    r=32, \n",
    "    lora_alpha=32, \n",
    "    target_modules=[\"q\", \"k\", \"v\"],\n",
    "    lora_dropout=0.1, \n",
    ")\n",
    "'''\n",
    "Args:\n",
    "    r (int): Lora attention dimension\n",
    "    target_modules (Union[List[str],str]): The names of the modules to apply Lora to.\n",
    "    lora_alpha (float): The alpha parameter for Lora scaling.\n",
    "    lora_dropout (float): The dropout probability for Lora layers. merge_weights (bool):\n",
    "        Whether to merge the weights of the Lora layers with the base transformer model in eval mode.\n",
    "    fan_in_fan_out (bool): Set this to True if the layer to replace stores weight like (fan_in, fan_out)\n",
    "    enable_lora ( List[bool]): Used with lora.MergedLinear.\n",
    "    bias (str): Bias type for Lora. Can be 'none', 'all' or 'lora_only'\n",
    "    modules_to_save (List[str]):List of modules apart from LoRA layers to be set as trainable\n",
    "        and saved in the final checkpoint.\n",
    "'''\n",
    "\n",
    "# LR = 2e-5\n",
    "LR = 8e-5\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "warm_up_ratio = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"warm_up_ratio\" 是一个术语，通常用于机器学习中的优化算法。它指的是在训练过程中，初始迭代步数中学习率的比例。具体来说，如果我们将整个训练过程分为若干个迭代步骤，那么 warm_up_ratio 就是指在训练开始时，前 warm_up_ratio 比例的迭代步骤中所使用的学习率较小，以帮助模型更好地适应数据分布，避免初始阶段出现过拟合等问题。在这个比例之后，学习率会逐渐增加，直到达到最大值，以便在后续的迭代步骤中更好地收敛到最优解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67260908731148b0b764debae0616e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>model = AutoModel.from_pretrained(checkpoint, trust_remote_code=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>deepspeed_plugin = DeepSpeedPlugin(zero_stage=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, gradient_accumulation_steps=accumulate_    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 # 精度控制</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 accelerator = Accelerator(mixed_precision=mixed_precision, gradient_accumulation_steps=a    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>device = accelerator.device                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 ### print setting</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">340</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 337 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fp8_recipe_handler = handler                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 338 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 339 │   │   </span>kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.init_handler.to_kwargs() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.init_handler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> {}   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 340 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state = AcceleratorState(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 341 │   │   │   </span>mixed_precision=mixed_precision,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 342 │   │   │   </span>cpu=cpu,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 343 │   │   │   </span>dynamo_plugin=dynamo_plugin,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">state.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">539</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">536 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> parse_flag_from_env(<span style=\"color: #808000; text-decoration-color: #808000\">\"ACCELERATE_USE_CPU\"</span>):                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">537 │   │   │   </span>cpu = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">538 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> PartialState._shared_state == {}:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>539 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>PartialState(cpu, **kwargs)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">540 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__dict__</span>.update(PartialState._shared_state)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">541 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._check_initialized(mixed_precision, cpu)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">542 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.initialized:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">state.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   │   │   </span>), <span style=\"color: #808000; text-decoration-color: #808000\">\"DeepSpeed is not available =&gt; install it using `pip3 install deepspe</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.distributed_type = DistributedType.DEEPSPEED                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> torch.distributed.is_initialized():                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>116 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>torch.distributed.init_process_group(backend=<span style=\"color: #808000; text-decoration-color: #808000\">\"nccl\"</span>, **kwargs)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_processes = torch.distributed.get_world_size()                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.process_index = torch.distributed.get_rank()                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/torch/distributed/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">distributed_c10d</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">754</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">init_process_group</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 751 │   │   │   </span>rendezvous_iterator = rendezvous(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 752 │   │   │   │   </span>init_method, rank, world_size, timeout=timeout                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 753 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 754 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>store, rank, world_size = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(rendezvous_iterator)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 755 │   │   │   </span>store.set_timeout(timeout)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 756 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 757 │   │   │   # Use a PrefixStore to avoid accidental overrides of keys used by</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/torch/distributed/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rendezvous.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">23</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_env_rendezvous_handler</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"rank\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> query_dict:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">234 │   │   </span>rank = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(query_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"rank\"</span>])                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>236 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>rank = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(_get_env_or_raise(<span style=\"color: #808000; text-decoration-color: #808000\">\"RANK\"</span>))                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">237 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"world_size\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> query_dict:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 │   │   </span>world_size = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(query_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"world_size\"</span>])                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/torch/distributed/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">rendezvous.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">22</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_env_or_raise</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_env_or_raise</span>(env_var: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   │   </span>env_val = os.environ.get(env_var, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> env_val:                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>221 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> _env_error(env_var)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">222 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> env_val                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Error initializing torch.distributed using env:<span style=\"color: #800080; text-decoration-color: #800080\">//</span> rendezvous: environment variable RANK expected, but \n",
       "not set\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mmodel = AutoModel.from_pretrained(checkpoint, trust_remote_code=\u001b[94mTrue\u001b[0m)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mdeepspeed_plugin = DeepSpeedPlugin(zero_stage=\u001b[94m2\u001b[0m, gradient_accumulation_steps=accumulate_    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m# 精度控制\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 6 accelerator = Accelerator(mixed_precision=mixed_precision, gradient_accumulation_steps=a    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mdevice = accelerator.device                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m### print setting\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m340\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 337 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.fp8_recipe_handler = handler                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 338 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 339 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs = \u001b[96mself\u001b[0m.init_handler.to_kwargs() \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.init_handler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m {}   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 340 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.state = AcceleratorState(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 341 \u001b[0m\u001b[2m│   │   │   \u001b[0mmixed_precision=mixed_precision,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 342 \u001b[0m\u001b[2m│   │   │   \u001b[0mcpu=cpu,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 343 \u001b[0m\u001b[2m│   │   │   \u001b[0mdynamo_plugin=dynamo_plugin,                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/accelerate/\u001b[0m\u001b[1;33mstate.py\u001b[0m:\u001b[94m539\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m536 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m parse_flag_from_env(\u001b[33m\"\u001b[0m\u001b[33mACCELERATE_USE_CPU\u001b[0m\u001b[33m\"\u001b[0m):                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m537 \u001b[0m\u001b[2m│   │   │   \u001b[0mcpu = \u001b[94mTrue\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m538 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m PartialState._shared_state == {}:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m539 \u001b[2m│   │   │   \u001b[0mPartialState(cpu, **kwargs)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m540 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__dict__\u001b[0m.update(PartialState._shared_state)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m541 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._check_initialized(mixed_precision, cpu)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m542 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.initialized:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/accelerate/\u001b[0m\u001b[1;33mstate.py\u001b[0m:\u001b[94m116\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m), \u001b[33m\"\u001b[0m\u001b[33mDeepSpeed is not available => install it using `pip3 install deepspe\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.distributed_type = DistributedType.DEEPSPEED                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m torch.distributed.is_initialized():                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m116 \u001b[2m│   │   │   │   │   \u001b[0mtorch.distributed.init_process_group(backend=\u001b[33m\"\u001b[0m\u001b[33mnccl\u001b[0m\u001b[33m\"\u001b[0m, **kwargs)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.num_processes = torch.distributed.get_world_size()                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.process_index = torch.distributed.get_rank()                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/torch/distributed/\u001b[0m\u001b[1;33mdistributed_c10d\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m754\u001b[0m in \u001b[92minit_process_group\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 751 \u001b[0m\u001b[2m│   │   │   \u001b[0mrendezvous_iterator = rendezvous(                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 752 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minit_method, rank, world_size, timeout=timeout                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 753 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 754 \u001b[2m│   │   │   \u001b[0mstore, rank, world_size = \u001b[96mnext\u001b[0m(rendezvous_iterator)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 755 \u001b[0m\u001b[2m│   │   │   \u001b[0mstore.set_timeout(timeout)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 756 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 757 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/torch/distributed/\u001b[0m\u001b[1;33mrendezvous.py\u001b[0m:\u001b[94m23\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m6\u001b[0m in \u001b[92m_env_rendezvous_handler\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mrank\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m query_dict:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   │   \u001b[0mrank = \u001b[96mint\u001b[0m(query_dict[\u001b[33m\"\u001b[0m\u001b[33mrank\u001b[0m\u001b[33m\"\u001b[0m])                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m236 \u001b[2m│   │   \u001b[0mrank = \u001b[96mint\u001b[0m(_get_env_or_raise(\u001b[33m\"\u001b[0m\u001b[33mRANK\u001b[0m\u001b[33m\"\u001b[0m))                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mworld_size\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m query_dict:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2m│   │   \u001b[0mworld_size = \u001b[96mint\u001b[0m(query_dict[\u001b[33m\"\u001b[0m\u001b[33mworld_size\u001b[0m\u001b[33m\"\u001b[0m])                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ypl/miniconda3/envs/ckqpy38/lib/python3.8/site-packages/torch/distributed/\u001b[0m\u001b[1;33mrendezvous.py\u001b[0m:\u001b[94m22\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92m_get_env_or_raise\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_env_or_raise\u001b[0m(env_var: \u001b[96mstr\u001b[0m) -> \u001b[96mstr\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   \u001b[0menv_val = os.environ.get(env_var, \u001b[94mNone\u001b[0m)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m env_val:                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m221 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m _env_error(env_var)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m env_val                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mError initializing torch.distributed using env:\u001b[35m/\u001b[0m\u001b[35m/\u001b[0m rendezvous: environment variable RANK expected, but \n",
       "not set\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "deepspeed_plugin = DeepSpeedPlugin(zero_stage=2, gradient_accumulation_steps=accumulate_step)# zero 2\n",
    "# 精度控制\n",
    "accelerator = Accelerator(mixed_precision=mixed_precision, gradient_accumulation_steps=accumulate_step, deepspeed_plugin=deepspeed_plugin)\n",
    "device = accelerator.device\n",
    "\n",
    "### print setting\n",
    "\n",
    "max_memory=accelerate.utils.get_max_memory()\n",
    "accelerator.print(\"max_memory\",max_memory)\n",
    "\n",
    "### Insert LoRA to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora.mark_only_lora_as_trainable(model)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "model_parameters = filter(lambda p: not p.requires_grad, model.parameters())\n",
    "non_trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "accelerator.print('trainable_params:{} ({:.2f}%), non_trainable_params:{}'.format(trainable_params, trainable_params/non_trainable_params*100,non_trainable_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKV_layer(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(QKV_layer, self).__init__()\n",
    "        self.linear_q = torch.nn.Linear(in_features, out_features//3)\n",
    "        self.linear_k = torch.nn.Linear(in_features, out_features//3)\n",
    "        self.linear_v = torch.nn.Linear(in_features, out_features//3)\n",
    "\n",
    "    def update(self, target_layer):\n",
    "        self.linear_q.weight.data = target_layer.weight[:target_layer.out_features//3, :].data\n",
    "        self.linear_q.bias.data = target_layer.bias[:target_layer.out_features//3].data\n",
    "\n",
    "        self.linear_k.weight.data = target_layer.weight[target_layer.out_features//3:target_layer.out_features//3*2, :].data\n",
    "        self.linear_k.bias.data = target_layer.bias[target_layer.out_features//3:target_layer.out_features//3*2].data\n",
    "\n",
    "        self.linear_v.weight.data = target_layer.weight[target_layer.out_features//3*2:, :].data\n",
    "        self.linear_v.bias.data = target_layer.bias[target_layer.out_features//3*2:].data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.linear_q(x)\n",
    "        k = self.linear_k(x)\n",
    "        v = self.linear_v(x)\n",
    "        return torch.concat([q,k,v], dim = -1)\n",
    "\n",
    "\n",
    "for key, module in model.named_modules():\n",
    "    if key.endswith('attention'):\n",
    "        if isinstance(module.query_key_value, peft.tuners.lora.LoraModel):\n",
    "            module.query_key_value = peft.tuners.lora.LoraModel(config, module.query_key_value.model)\n",
    "        else:\n",
    "            # Here we split the query_key_value layer into three linear layer for LoRA. But you can also use merged linear.\n",
    "            qkv_layer = QKV_layer(module.query_key_value.in_features, module.query_key_value.out_features) \n",
    "            qkv_layer.update(module.query_key_value)\n",
    "            module.query_key_value = qkv_layer\n",
    "            module.query_key_value = peft.tuners.lora.LoraModel(config, module.query_key_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 数据处理\n",
    "### Dataset\n",
    "\n",
    "EOS_ID = 150005\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open('data/alpaca_data.json', 'r') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for line in content:\n",
    "    if line['input'] == '':\n",
    "        prompt = PROMPT_DICT['prompt_no_input'].format_map(line)\n",
    "    else:\n",
    "        prompt = PROMPT_DICT['prompt_input'].format_map(line)\n",
    "    completion = line['output']+'</s>'\n",
    "    if len(prompt) + len(completion) < MAX_LENGTH:\n",
    "        pairs.append({'prompt':prompt, 'completion':completion})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## jupyter notebook\n",
    "from accelerate import notebook_launcher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckqpy38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d8bdb44f3e9a5714bc2974b8edd400dea31ee2ae63ed4830807e434c750c669"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
